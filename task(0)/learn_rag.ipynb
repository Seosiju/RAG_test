{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7dd2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader # type: ignore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # type: ignore\n",
    "from langchain_community.vectorstores import FAISS # type: ignore\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings # type: ignore\n",
    "from langchain_community.chat_models import ChatOllama # type: ignore\n",
    "from langchain_core.prompts import ChatPromptTemplate # type: ignore\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain # type: ignore\n",
    "from langchain.chains import create_retrieval_chain # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ff54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 문서 로드 (Load)\n",
    "# 답변의 근거가 될 PDF 문서를 로드합니다.\n",
    "from pathlib import Path\n",
    "pdf_path = Path(\"/Users/snu.sim/git/RAG_test/The Ghost in the Machine.pdf\")\n",
    "loader = PyPDFLoader(str(pdf_path))\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c3fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 문서 분할 (Split)\n",
    "# 문서를 검색하기 좋은 크기의 여러 조각(청크)으로 나눕니다.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a360c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')), '(Request ID: bafdd925-a450-408a-b135-abcfe117fc23)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c82b73be92440d82e989c65b71b0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14de71fcb5404cf9853a65f148dd2681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a37c60114cc48ac9a3722de048d576f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84fb68b98fe47be957ae224e771a3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b20487345a442295032c76783c6ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b1f6a87ca64550b8c922904ff290e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee13662881fb4c9394c0b5bf4254b0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a78446c3d2f44079a62552511db7d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd87a8cd9eb4058a17bb5603182fc03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5113d91296fe47fd9e217dfe540ebf0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9c0c945c2d41dc9d9b0d4cff418f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. 임베딩 & 벡터 스토어 생성 (Store)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\", # Huggingface 모델명\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3907dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분할된 문서를 임베딩하여 FAISS 벡터 스토어에 저장합니다. (메모리 기반)\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db0f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 검색기(Retriever) 생성\n",
    "# 벡터 스토어에서 관련 문서를 검색하는 역할을 합니다.\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b11a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2q/_8m2fvxd4pv04q2b3gk8j0bm0000gn/T/ipykernel_19744/896109414.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"gemma3:4b\")\n"
     ]
    }
   ],
   "source": [
    "# 5. LLM 로드 (Ollama 연동)\n",
    "# 로컬에서 실행 중인 Ollama의 모델을 LangChain에서 사용할 수 있도록 설정합니다.\n",
    "llm = ChatOllama(model=\"gemma3:4b\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b6fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 프롬프트 정의\n",
    "# LLM에게 질문과 함께 검색된 문서를 어떻게 활용할지 지시하는 템플릿입니다.\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a2d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. RAG 체인 생성\n",
    "# LangChain Expression Language (LCEL)을 사용하여 체인을 구성합니다.\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# 8. 체인 실행 및 질문\n",
    "response = retrieval_chain.invoke({\"input\": \"Adapter BERT의 저자가 누구야?\"})\n",
    "\n",
    "# 답변 출력\n",
    "# 답변의 근거가 된 문서(Context) 출력\n",
    "print(\"---------- 검색된 근거 문서 ----------\\n\")\n",
    "for i, doc in enumerate(response[\"context\"]):\n",
    "    print(f\"문서 #{i+1}:\\n\")\n",
    "    print(doc.page_content)\n",
    "    print(\"\\n------------------------------------\\n\")\n",
    "\n",
    "# 최종 답변 출력\n",
    "print(\"---------- AI 최종 답변 ----------\\n\")\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
